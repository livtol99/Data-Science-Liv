{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laoding packages\n",
    "# General packages\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from time import time\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Data processing and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# Machine learning and forecasting\n",
    "import darts\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts import TimeSeries\n",
    "from darts.models import TransformerModel, ExponentialSmoothing\n",
    "from darts.metrics import mape\n",
    "from darts.utils.statistics import check_seasonality, plot_acf\n",
    "\n",
    "\n",
    "# PySpark for distributed processing\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "\n",
    "# Custom functions\n",
    "%run functions.py\n",
    "\n",
    "from darts.utils.utils import ModelMode\n",
    "from darts.utils.utils import SeasonalityMode\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping the cluster code over all cluster data sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing it with Holt's linear trend instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the folder\n",
    "data_folder_path = '/work/Data-Science-Liv/Data/clustered_data'\n",
    "forecast_folder_path = '/work/Data-Science-Liv/Data/holt_cluster_forecasts'\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "if not os.path.exists(forecast_folder_path):\n",
    "    os.makedirs(forecast_folder_path)\n",
    "\n",
    "# Define the file pattern to match\n",
    "file_pattern = 'long_cluster_*_full.csv'\n",
    "\n",
    "# Get a list of file paths that match the pattern\n",
    "data_file_paths = glob.glob(f\"{data_folder_path}/{file_pattern}\")\n",
    "\n",
    "# Initialize empty dictionaries to store forecasts for each cluster\n",
    "forecasts_clusters = {}\n",
    "\n",
    "# Iterate over the file paths\n",
    "for data_file_path in data_file_paths:\n",
    "    \n",
    "    # Extract the cluster number from the file name\n",
    "    match = re.search(r'long_cluster_(\\d+)_full.csv', data_file_path)\n",
    "    if match:\n",
    "        cluster = int(match.group(1))\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(data_file_path, parse_dates=['Year'])\n",
    "\n",
    "    # Create test and train splits\n",
    "    train_df, test_df = create_splits(df)\n",
    "\n",
    "    # Obtain the representative train ts via yearly aggregation across all individual time series in the current cluster\n",
    "    representative_df_train = create_representative_train(train_df)\n",
    "\n",
    "    # Convert representative_df_train to a Darts TimeSeries object\n",
    "    representative_ts_train = TimeSeries.from_dataframe(representative_df_train, 'ds', 'y')\n",
    "\n",
    "    # Define model to be fit to the representative\n",
    "    #Using Holt's Holtâ€™s exponential smoothing.\n",
    "    model = ExponentialSmoothing(trend=ModelMode.ADDITIVE, seasonal=SeasonalityMode.NONE, damped = True)\n",
    "\n",
    "    # Fit model to representative train ts\n",
    "    model.fit(representative_ts_train)\n",
    "\n",
    "    #  Obtain the representative test ts\n",
    "    representative_df_test = create_representative_test(test_df)\n",
    "\n",
    "    #Generate forecasts on the test period for the representative test ts - NB! leaving out the actual test data via .drop('y', axis =1)\n",
    "    representative_forecasts_ts = model.predict(n=10)\n",
    "\n",
    "    # Convert representative_forecasts to a DataFrame\n",
    "    representative_forecasts_df = pd.DataFrame({'ds': representative_forecasts_ts.time_index, 'yhat': representative_forecasts_ts.univariate_values()})\n",
    "\n",
    "    #Merge the forecasts with the test DataFrame\n",
    "    representative_forecasts_merged = pd.merge(representative_df_test[['ds']], representative_forecasts_df, on='ds', how='inner')\n",
    "\n",
    "    # Create the adjustment series and combine together train, test, and all adjustment series\n",
    "    df_actual_all = create_adjustment_series(train_df, test_df, representative_df_train, representative_df_test, representative_forecasts_merged)\n",
    "\n",
    "    ####  Generate forecasts for each countries time series \n",
    "\n",
    "    #Create adjustment forecasts  by fitting a simple linear model to the adjustment series\n",
    "    adjustment_forecasts_df = df_actual_all.groupby(['Country']).apply(lambda x: get_linear_model_pred(x, representative_df_test)).reset_index(drop=False)\n",
    "    adjustment_forecasts_df = adjustment_forecasts_df.rename(columns={'Year': 'ds'})\n",
    "\n",
    "    #Merge all data so far with the adjustment forecasts\n",
    "    final_output = pd.merge(df_actual_all, adjustment_forecasts_df, on=['Country', 'ds'], how='left')\n",
    "\n",
    "    #Create forecasts for all individual time series in a cluster by adding together the representative forecasys and adjustment forecasts\n",
    "    final_output['final_prediction'] = final_output['yhat'] + final_output['adjustment_Forecasts_test']\n",
    "\n",
    "    # Store forecasts in a diactionary based on the current cluster\n",
    "    #We only want the columns relevant for the actual final forecasts (the training columns y_tr, y_repr_tr, adjusted_val, are thus not interesting)\n",
    "    # Assuming `final_output` is the original DataFrame\n",
    "    selected_columns = ['Country', 'ds', 'y_tst', 'yhat', 'level_1', 'adjustment_Forecasts_test', 'final_prediction']\n",
    "    forecasts_clusters[cluster] = final_output[selected_columns]\n",
    "\n",
    "\n",
    "    # Save the current forecast DataFrame as a CSV file\n",
    "    file_name = f'holt_forecasts_cluster{cluster}.csv'\n",
    "    file_path = os.path.join(forecast_folder_path, file_name)\n",
    "    forecasts_clusters[cluster].to_csv(file_path, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
