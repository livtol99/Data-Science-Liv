{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laoding packages\n",
    "# General packages\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from time import time\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Data processing and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# Machine learning and forecasting\n",
    "import darts\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts import TimeSeries\n",
    "from darts.models import TransformerModel, ExponentialSmoothing\n",
    "from darts.metrics import mape\n",
    "from darts.utils.statistics import check_seasonality, plot_acf\n",
    "\n",
    "\n",
    "# PySpark for distributed processing\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "\n",
    "# Custom functions\n",
    "%run functions.py\n",
    "\n",
    "from darts.utils.utils import ModelMode\n",
    "from darts.utils.utils import SeasonalityMode\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series forecasting with Prophet\n",
    "# import prophet\n",
    "# from prophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping the cluster code over all cluster data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Prophet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/work/Data-Science-Liv/Code/running_cluster_model.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://app-785606-0.cloud.sdu.dk/work/Data-Science-Liv/Code/running_cluster_model.ipynb#ch0000002vscode-remote?line=36'>37</a>\u001b[0m representative_df_train \u001b[39m=\u001b[39m create_representative_train(train_df)\n\u001b[1;32m     <a href='vscode-notebook-cell://app-785606-0.cloud.sdu.dk/work/Data-Science-Liv/Code/running_cluster_model.ipynb#ch0000002vscode-remote?line=38'>39</a>\u001b[0m \u001b[39m# Define model to be fit to the representative\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://app-785606-0.cloud.sdu.dk/work/Data-Science-Liv/Code/running_cluster_model.ipynb#ch0000002vscode-remote?line=39'>40</a>\u001b[0m model \u001b[39m=\u001b[39m Prophet(\n\u001b[1;32m     <a href='vscode-notebook-cell://app-785606-0.cloud.sdu.dk/work/Data-Science-Liv/Code/running_cluster_model.ipynb#ch0000002vscode-remote?line=40'>41</a>\u001b[0m     growth\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://app-785606-0.cloud.sdu.dk/work/Data-Science-Liv/Code/running_cluster_model.ipynb#ch0000002vscode-remote?line=41'>42</a>\u001b[0m     seasonality_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmultiplicative\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://app-785606-0.cloud.sdu.dk/work/Data-Science-Liv/Code/running_cluster_model.ipynb#ch0000002vscode-remote?line=42'>43</a>\u001b[0m     seasonality_prior_scale \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m, \u001b[39m# A small value here dampens the seasonality - we do this because there really is no seasonality in our data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://app-785606-0.cloud.sdu.dk/work/Data-Science-Liv/Code/running_cluster_model.ipynb#ch0000002vscode-remote?line=43'>44</a>\u001b[0m     yearly_seasonality\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://app-785606-0.cloud.sdu.dk/work/Data-Science-Liv/Code/running_cluster_model.ipynb#ch0000002vscode-remote?line=44'>45</a>\u001b[0m     weekly_seasonality\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://app-785606-0.cloud.sdu.dk/work/Data-Science-Liv/Code/running_cluster_model.ipynb#ch0000002vscode-remote?line=45'>46</a>\u001b[0m     daily_seasonality\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://app-785606-0.cloud.sdu.dk/work/Data-Science-Liv/Code/running_cluster_model.ipynb#ch0000002vscode-remote?line=47'>48</a>\u001b[0m \u001b[39m# Fit model to representative train ts\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://app-785606-0.cloud.sdu.dk/work/Data-Science-Liv/Code/running_cluster_model.ipynb#ch0000002vscode-remote?line=48'>49</a>\u001b[0m model\u001b[39m.\u001b[39mfit(representative_df_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Prophet' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the path to the folder\n",
    "data_folder_path = '/work/Data-Science-Liv/clustered_data'\n",
    "forecast_folder_path = '/work/Data-Science-Liv/cluster_forecasts'\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "if not os.path.exists(data_folder_path):\n",
    "    os.makedirs(data_folder_path)\n",
    "\n",
    "if not os.path.exists(forecast_folder_path):\n",
    "    os.makedirs(forecast_folder_path)\n",
    "\n",
    "# Define the file pattern to match\n",
    "file_pattern = 'long_cluster_*_full.csv'\n",
    "\n",
    "# Get a list of file paths that match the pattern\n",
    "data_file_paths = glob.glob(f\"{data_folder_path}/{file_pattern}\")\n",
    "\n",
    "# Initialize empty dictionaries to store forecasts for each cluster\n",
    "forecasts_clusters = {}\n",
    "\n",
    "# Iterate over the file paths\n",
    "for data_file_path in data_file_paths:\n",
    "    \n",
    "    # Extract the cluster number from the file name\n",
    "    match = re.search(r'long_cluster_(\\d+)_full.csv', data_file_path)\n",
    "    if match:\n",
    "        cluster = int(match.group(1))\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(data_file_path, parse_dates=['Year'])\n",
    "\n",
    "    # Create test and train splits\n",
    "    train_df, test_df = create_splits(df)\n",
    "\n",
    "    # Obtain the representative train ts via yearly aggregation across all individual time series in the current cluster\n",
    "    representative_df_train = create_representative_train(train_df)\n",
    "\n",
    "    # Define model to be fit to the representative\n",
    "    model = Prophet(\n",
    "        growth='linear',\n",
    "        seasonality_mode='multiplicative',\n",
    "        seasonality_prior_scale = 0.001, # A small value here dampens the seasonality - we do this because there really is no seasonality in our data\n",
    "        yearly_seasonality=False,\n",
    "        weekly_seasonality=False,\n",
    "        daily_seasonality=False)\n",
    "\n",
    "    # Fit model to representative train ts\n",
    "    model.fit(representative_df_train)\n",
    "\n",
    "    #  Obtain the representative test ts\n",
    "    representative_df_test = create_representative_test(test_df)\n",
    "    \n",
    "    #Generate forecasts on the test period for the representative test ts - NB! leaving out the actual test data via .drop('y', axis =1)\n",
    "    representative_forecasts = model.predict(df=representative_df_test.drop('y', axis=1))\n",
    "\n",
    "    # Create the adjustment series and combine together train, test and all adjustment series\n",
    "    df_actual_all = create_adjustment_series(train_df, test_df, representative_df_train, representative_df_test, representative_forecasts)\n",
    "\n",
    "    ####  Generate forecasts for each countries time series \n",
    "\n",
    "    #Create adjustment forecasts  by fitting a simple linear model to the adjustment series\n",
    "    adjustment_forecasts_df = df_actual_all.groupby(['Country']).apply(lambda x: get_linear_model_pred(x, representative_df_test)).reset_index(drop=False)\n",
    "    adjustment_forecasts_df = adjustment_forecasts_df.rename(columns={'Year': 'ds'})\n",
    "\n",
    "    #Merge all data so far with the adjustment forecasts\n",
    "    final_output = pd.merge(df_actual_all, adjustment_forecasts_df, on=['Country', 'ds'], how='left')\n",
    "    \n",
    "    #Create forecasts for all individual time series in a cluster by adding together the representative forecasys and adjustment forecasts\n",
    "    final_output['final_prediction'] = final_output['yhat'] + final_output['adjustment_Forecasts_test']\n",
    "\n",
    "    # Store forecasts in a diactionary based on the current cluster\n",
    "    #We only want the columns relevant for the actual final forecasts (the training columns y_tr, y_repr_tr, adjusted_val, are thus not interesting)\n",
    "    # Assuming `final_output` is the original DataFrame\n",
    "    selected_columns = ['Country', 'ds', 'y_tst', 'yhat', 'level_1', 'adjustment_Forecasts_test', 'final_prediction']\n",
    "    forecasts_clusters[cluster] = final_output[selected_columns]\n",
    "\n",
    "\n",
    "    # Save the current forecast DataFrame as a CSV file\n",
    "    file_name = f'forecasts_cluster{cluster}.csv'\n",
    "    file_path = os.path.join(forecast_folder_path, file_name)\n",
    "    forecasts_clusters[cluster].to_csv(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing it with Holt's linear trend instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the folder\n",
    "data_folder_path = '/work/Data-Science-Liv/clustered_data'\n",
    "forecast_folder_path = '/work/Data-Science-Liv/holt_cluster_forecasts'\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "if not os.path.exists(forecast_folder_path):\n",
    "    os.makedirs(forecast_folder_path)\n",
    "\n",
    "# Define the file pattern to match\n",
    "file_pattern = 'long_cluster_*_full.csv'\n",
    "\n",
    "# Get a list of file paths that match the pattern\n",
    "data_file_paths = glob.glob(f\"{data_folder_path}/{file_pattern}\")\n",
    "\n",
    "# Initialize empty dictionaries to store forecasts for each cluster\n",
    "forecasts_clusters = {}\n",
    "\n",
    "# Iterate over the file paths\n",
    "for data_file_path in data_file_paths:\n",
    "    \n",
    "    # Extract the cluster number from the file name\n",
    "    match = re.search(r'long_cluster_(\\d+)_full.csv', data_file_path)\n",
    "    if match:\n",
    "        cluster = int(match.group(1))\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(data_file_path, parse_dates=['Year'])\n",
    "\n",
    "    # Create test and train splits\n",
    "    train_df, test_df = create_splits(df)\n",
    "\n",
    "    # Obtain the representative train ts via yearly aggregation across all individual time series in the current cluster\n",
    "    representative_df_train = create_representative_train(train_df)\n",
    "\n",
    "    # Convert representative_df_train to a Darts TimeSeries object\n",
    "    representative_ts_train = TimeSeries.from_dataframe(representative_df_train, 'ds', 'y')\n",
    "\n",
    "    # Define model to be fit to the representative\n",
    "    #Using Holt's Holt’s exponential smoothing.\n",
    "    model = ExponentialSmoothing(trend=ModelMode.ADDITIVE, seasonal=SeasonalityMode.NONE, damped = True)\n",
    "\n",
    "    # Fit model to representative train ts\n",
    "    model.fit(representative_ts_train)\n",
    "\n",
    "    #  Obtain the representative test ts\n",
    "    representative_df_test = create_representative_test(test_df)\n",
    "\n",
    "    #Generate forecasts on the test period for the representative test ts - NB! leaving out the actual test data via .drop('y', axis =1)\n",
    "    representative_forecasts_ts = model.predict(n=10)\n",
    "\n",
    "    # Convert representative_forecasts to a DataFrame\n",
    "    representative_forecasts_df = pd.DataFrame({'ds': representative_forecasts_ts.time_index, 'yhat': representative_forecasts_ts.univariate_values()})\n",
    "\n",
    "    #Merge the forecasts with the test DataFrame\n",
    "    representative_forecasts_merged = pd.merge(representative_df_test[['ds']], representative_forecasts_df, on='ds', how='inner')\n",
    "\n",
    "    # Create the adjustment series and combine together train, test, and all adjustment series\n",
    "    df_actual_all = create_adjustment_series(train_df, test_df, representative_df_train, representative_df_test, representative_forecasts_merged)\n",
    "\n",
    "    ####  Generate forecasts for each countries time series \n",
    "\n",
    "    #Create adjustment forecasts  by fitting a simple linear model to the adjustment series\n",
    "    adjustment_forecasts_df = df_actual_all.groupby(['Country']).apply(lambda x: get_linear_model_pred(x, representative_df_test)).reset_index(drop=False)\n",
    "    adjustment_forecasts_df = adjustment_forecasts_df.rename(columns={'Year': 'ds'})\n",
    "\n",
    "    #Merge all data so far with the adjustment forecasts\n",
    "    final_output = pd.merge(df_actual_all, adjustment_forecasts_df, on=['Country', 'ds'], how='left')\n",
    "\n",
    "    #Create forecasts for all individual time series in a cluster by adding together the representative forecasys and adjustment forecasts\n",
    "    final_output['final_prediction'] = final_output['yhat'] + final_output['adjustment_Forecasts_test']\n",
    "\n",
    "    # Store forecasts in a diactionary based on the current cluster\n",
    "    #We only want the columns relevant for the actual final forecasts (the training columns y_tr, y_repr_tr, adjusted_val, are thus not interesting)\n",
    "    # Assuming `final_output` is the original DataFrame\n",
    "    selected_columns = ['Country', 'ds', 'y_tst', 'yhat', 'level_1', 'adjustment_Forecasts_test', 'final_prediction']\n",
    "    forecasts_clusters[cluster] = final_output[selected_columns]\n",
    "\n",
    "\n",
    "    # Save the current forecast DataFrame as a CSV file\n",
    "    file_name = f'holt_forecasts_cluster{cluster}.csv'\n",
    "    file_path = os.path.join(forecast_folder_path, file_name)\n",
    "    forecasts_clusters[cluster].to_csv(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just assessing code for one cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/work/Data-Science-Liv/clustered_data/long_cluster_2_full.csv', parse_dates=['Year'])\n",
    "\n",
    "# # Create test and train splits\n",
    "# train_df, test_df = create_splits(df)\n",
    "\n",
    "#  # Obtain the representative train ts via yearly aggregation across all individual time series in the current cluster\n",
    "# representative_df_train = create_representative_train(train_df)\n",
    "\n",
    "# # Convert representative_df_train to a Darts TimeSeries object\n",
    "# representative_ts_train = TimeSeries.from_dataframe(representative_df_train, 'ds', 'y')\n",
    "\n",
    "# # Define model to be fit to the representative\n",
    "# #Using Holt's Holt’s exponential smoothing.\n",
    "# model = ExponentialSmoothing(trend=ModelMode.ADDITIVE, seasonal=SeasonalityMode.NONE, damped = True)\n",
    "\n",
    "# # Fit model to representative train ts\n",
    "# model.fit(representative_ts_train)\n",
    "\n",
    "# #  Obtain the representative test ts\n",
    "# representative_df_test = create_representative_test(test_df)\n",
    "\n",
    "# #Generate forecasts on the test period for the representative test ts - NB! leaving out the actual test data via .drop('y', axis =1)\n",
    "# representative_forecasts_ts = model.predict(n=10)\n",
    "\n",
    "# # Convert representative_forecasts to a DataFrame\n",
    "# representative_forecasts_df = pd.DataFrame({'ds': representative_forecasts_ts.time_index, 'yhat': representative_forecasts_ts.univariate_values()})\n",
    "\n",
    "# #Merge the forecasts with the test DataFrame\n",
    "# representative_forecasts_merged = pd.merge(representative_df_test[['ds']], representative_forecasts_df, on='ds', how='inner')\n",
    "\n",
    "# # Create the adjustment series and combine together train, test, and all adjustment series\n",
    "# df_actual_all = create_adjustment_series(train_df, test_df, representative_df_train, representative_df_test, representative_forecasts_merged)\n",
    "\n",
    "# ####  Generate forecasts for each countries time series \n",
    "\n",
    "# #Create adjustment forecasts  by fitting a simple linear model to the adjustment series\n",
    "# adjustment_forecasts_df = df_actual_all.groupby(['Country']).apply(lambda x: get_linear_model_pred(x, representative_df_test)).reset_index(drop=False)\n",
    "# adjustment_forecasts_df = adjustment_forecasts_df.rename(columns={'Year': 'ds'})\n",
    "\n",
    "# #Merge all data so far with the adjustment forecasts\n",
    "# final_output = pd.merge(df_actual_all, adjustment_forecasts_df, on=['Country', 'ds'], how='left')\n",
    "\n",
    "# #Create forecasts for all individual time series in a cluster by adding together the representative forecasys and adjustment forecasts\n",
    "# final_output['final_prediction'] = final_output['yhat'] + final_output['adjustment_Forecasts_test']\n",
    "\n",
    "# # Store forecasts in a diactionary based on the current cluster\n",
    "# #We only want the columns relevant for the actual final forecasts (the training columns y_tr, y_repr_tr, adjusted_val, are thus not interesting)\n",
    "# # Assuming `final_output` is the original DataFrame\n",
    "# selected_columns = ['Country', 'ds', 'y_tst', 'yhat', 'level_1', 'adjustment_Forecasts_test', 'final_prediction']\n",
    "# forecasts_clusters[cluster] = final_output[selected_columns]\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
